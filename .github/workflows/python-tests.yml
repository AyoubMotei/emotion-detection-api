# -------------------------------------------------------------------------
# 1. Configuration Générale du Workflow
# -------------------------------------------------------------------------
name: CI - Tests Unitaires du Projet

# Déclenche le workflow (quand et comment il doit s'exécuter)
on:
  push:
    # Exécuter lorsque des commits sont poussés sur les branches principales
    branches: ["main", "master"]
  pull_request:
    # Exécuter lorsque des Pull Requests sont ouvertes ou mises à jour
    branches: ["main", "master"]

# -------------------------------------------------------------------------
# 2. Définition des Tâches (Jobs)
# -------------------------------------------------------------------------
jobs:
  test:
    # Nom du système d'exploitation où le job va s'exécuter
    runs-on: ubuntu-latest

    # --- Configuration du service PostgreSQL (via Docker géré par GH Actions) ---
    # Cette section démarre une base de données temporaire pour que les tests SQLAlchemy
    # de votre application FastAPI puissent se connecter et créer des tables.
    services:
      postgres:
        image: postgres:16 # Utiliser l'image Docker officielle de Postgres
        env:
          # Définition des identifiants et du nom de la base de données de test
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: "test_password"
          POSTGRES_DB: emotions_db
        ports:
          # Mappe le port 5432 du conteneur au port 5432 de l'hôte
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U test_user -d emotions_db"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

    # -------------------------------------------------------------------------
    # 2.2. Étapes (Steps): Les actions à exécuter
    # -------------------------------------------------------------------------
    steps:
      - name: 1. Cloner le repository
        # Récupère le code de votre projet sur la machine de la CI
        uses: actions/checkout@v4

      - name: 2. Configurer Python 3.10
        uses: actions/setup-python@v4
        with:
          # Utilise une version de Python stable et largement supportée
          python-version: "3.10"

      - name: 3. Installer le client PostgreSQL (psql)
        # Nécessaire pour l'étape d'attente de connexion à la DB et le débogage éventuel
        run: |
          sudo apt-get update -y
          sudo apt-get install -y postgresql-client

      - name: 4. Installer les dépendances Python
        run: |
          python -m pip install --upgrade pip
          # Installation des packages listés dans requirement.txt (ou requirements.txt)
          if [ -f "requirement.txt" ]; then
            pip install -r requirement.txt
          elif [ -f "requirements.txt" ]; then
            pip install -r requirements.txt
          fi
          # Ajout des outils nécessaires aux tests (pytest, httpx pour les requêtes)
          pip install pytest httpx python-dotenv

      - name: 5. Configurer PYTHONPATH
        # Ajoute les dossiers racine et 'src' au chemin d'importation de Python
        # Cela permet à Pytest d'importer correctement vos modules (ex: from src.main import app)
        run: |
          echo "PYTHONPATH=$(pwd):$(pwd)/src" >> $GITHUB_ENV

      - name: 6. Attendre que Postgres soit prêt (Vérification de connexion)
        # Cette boucle essaie de se connecter à la DB de test jusqu'à ce qu'elle soit opérationnelle.
        run: |
          until psql "postgresql://test_user:test_password@localhost:5432/emotions_db" -c '\q'; do
            echo "Postgres inaccessible - attente 1s"
            sleep 1
          done
          echo "Postgres est prêt."

      - name: 7. Exporter les variables d'environnement de la DB
        # Définit les variables d'environnement que votre fichier `src/database.py` utilise.
        run: |
          echo "user=test_user" >> $GITHUB_ENV
          echo "password=test_password" >> $GITHUB_ENV
          echo "host=localhost" >> $GITHUB_ENV
          echo "port=5432" >> $GITHUB_ENV
          echo "database=emotions_db" >> $GITHUB_ENV
          echo "DATABASE_URL=postgresql://test_user:test_password@localhost:5432/emotions_db" >> $GITHUB_ENV


      - name: 8. Préparer les Artifacts Machine Learning
        # Télécharge le fichier nécessaire au module 'detect_and_predict.py' (Haar Cascade)
        # et crée un fichier .h5 factice pour que le code puisse s'importer sans erreur.
        run: |
          mkdir -p models 
          wget -q -O haarcascade_frontalface_default.xml \
            https://raw.githubusercontent.com/opencv/opencv/4.x/data/haarcascades/haarcascades/haarcascade_frontalface_default.xml || true
          if [ ! -f "models/emotion_model.h5" ]; then
            touch models/emotion_model.h5
          fi

      - name: 9. Créer les Tables de la Base de Données (SQLAlchemy)
        # Exécute la logique de création des tables de votre application.
        # Utilise le code Python pour s'assurer que la base de données est initialisée avant les tests.
        run: |
          python -c "from src.main import Base, engin; Base.metadata.create_all(bind=engin); print('Tables créées.')"


      - name: 10. Lancer les Tests Unitaires
        # Exécute Pytest sur tout le code de l'application et calcule la couverture de code.
        run: |
          python -m pytest -v --cov=src